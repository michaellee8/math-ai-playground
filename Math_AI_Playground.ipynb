{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Math AI Playground\n",
    "\n",
    "- Evaluate numeric-only math expression step by step.\n",
    "- Expression length cannot be more than 20 characters.\n",
    "- Support `*` and `+` only, `-` and `()` support will be attempted later. Intended for the neural network to learn the rules of mathematics.\n",
    "- Support integers only.\n",
    "\n",
    "Character encoding:\n",
    "\n",
    "| Character | Token    |\n",
    "|-----------|----------|\n",
    "| 0         | 0        |\n",
    "| 1         | 1        |\n",
    "| 2         | 2        |\n",
    "| 3         | 3        |\n",
    "| 4         | 4        |\n",
    "| 5         | 5        |\n",
    "| 6         | 6        |\n",
    "| 7         | 7        |\n",
    "| 8         | 8        |\n",
    "| 9         | 9        |\n",
    "| *         | 10       |\n",
    "| +         | 11       |\n",
    "| -         | 12       |\n",
    "|  (space)  | 13       |"
   ],
   "metadata": {
    "id": "0D05WkvbNyKV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Global imports\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import random\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "randomer = random.Random(1)"
   ],
   "metadata": {
    "id": "3hbiwGEcllLk"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "CHAR_TOKEN_MAP = {\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    '5': 5,\n",
    "    '6': 6,\n",
    "    '7': 7,\n",
    "    '8': 8,\n",
    "    '9': 9,\n",
    "    '*': 10,\n",
    "    '+': 11,\n",
    "    '-': 12,\n",
    "    ' ': 13\n",
    "}\n",
    "\n",
    "TOKEN_CHAR_MAP = {}\n",
    "\n",
    "for k, v in CHAR_TOKEN_MAP.items():\n",
    "    TOKEN_CHAR_MAP[v] = k\n",
    "\n",
    "TOKEN_CHAR_MAP"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmHyuJtJnrh0",
    "outputId": "d2c9ba0e-5504-42aa-fc80-a9ee81cd778a"
   },
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: '0',\n 1: '1',\n 2: '2',\n 3: '3',\n 4: '4',\n 5: '5',\n 6: '6',\n 7: '7',\n 8: '8',\n 9: '9',\n 10: '*',\n 11: '+',\n 12: '-',\n 13: ' '}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '*', '+', '-', ' ']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHAR_VOCAB = list(CHAR_TOKEN_MAP)\n",
    "CHAR_VOCAB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data generation"
   ],
   "metadata": {
    "id": "NTl_rwTlialX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVsqBeNQNd9_",
    "outputId": "39c2e0c3-87f5-4ece-f7a7-3810a22f682e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['29*41+77+31+6       ',\n '1189+77+31+6        ',\n '1266+31+6           ',\n '1297+6              ',\n '1303                ']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIGIT_CHARS = list('0123456789')\n",
    "OP_CHARS = list('*+')\n",
    "EXPRESSION_LENGTH = 20\n",
    "TOKEN_SPACE_SIZE = 16\n",
    "\n",
    "def generate_initial_expression(rand: random.Random) -> str:\n",
    "    initial_expression = [rand.choice(DIGIT_CHARS) if i % 3 < 2 else rand.choice(OP_CHARS) for i in range(14)]\n",
    "    if initial_expression[0] == '0':\n",
    "        initial_expression = initial_expression[1:]\n",
    "    initial_expression = re.sub(\"([\\*\\+\\-])0\", lambda mo: mo.group(1), ''.join(initial_expression))\n",
    "    \n",
    "    return initial_expression\n",
    "\n",
    "# Evaluate one step of the expression, return expression, False if no further\n",
    "# steps can be made anymore.\n",
    "def progress_expression_step(expression: str) -> Tuple[str, bool]:\n",
    "    op = ''\n",
    "    op_idx = -1\n",
    "\n",
    "    if '*' in expression:\n",
    "        # Multiplication takes precendence\n",
    "        op = '*'\n",
    "        op_idx = expression.find('*')\n",
    "    else:\n",
    "        m = re.search('\\+', expression)\n",
    "        if m is not None:\n",
    "            op = expression[m.start()]\n",
    "            op_idx = m.start()\n",
    "    \n",
    "    if op == ' ' or op_idx == -1:\n",
    "        return expression, False\n",
    "    \n",
    "    start_idx = op_idx - 1\n",
    "    end_idx = op_idx + 1\n",
    "\n",
    "    while start_idx - 1 >= 0 and expression[start_idx - 1] not in OP_CHARS:\n",
    "        start_idx -= 1\n",
    "    \n",
    "    while end_idx + 1 < len(expression) and expression[end_idx + 1] not in OP_CHARS:\n",
    "        end_idx += 1\n",
    "\n",
    "    num1 = int(expression[start_idx:op_idx])\n",
    "    num2 = int(expression[op_idx+1:end_idx+1])\n",
    "\n",
    "    calc_result = 0\n",
    "\n",
    "    if op == '*':\n",
    "        calc_result = num1 * num2\n",
    "    elif op == '+':\n",
    "        calc_result = num1 + num2\n",
    "    elif op == '-':\n",
    "        calc_result = num1 - num2\n",
    "\n",
    "    before_result = expression[:start_idx]\n",
    "    after_result = expression[end_idx+1:]\n",
    "\n",
    "    if len(before_result) > 0 and calc_result < 0:\n",
    "        if before_result[-1] == '-':\n",
    "            before_result[-1] = '+'\n",
    "        elif before_result[-1] == '+':\n",
    "            before_result[-1] = '-'\n",
    "    \n",
    "    calc_result = abs(calc_result)\n",
    "\n",
    "    return before_result + str(calc_result) + after_result, True\n",
    "    \n",
    "\n",
    "def generate_expression_with_steps(rand: random.Random) -> List[str]:\n",
    "    initial_expression = generate_initial_expression(rand)\n",
    "    ret = [initial_expression]\n",
    "    while True:\n",
    "        exp, has_further = progress_expression_step(ret[-1])\n",
    "        if not has_further:\n",
    "            break\n",
    "        ret.append(exp)\n",
    "    if int(eval(initial_expression)) != int(ret[-1]):\n",
    "        raise ValueError(\"internal logic error, value evaluation is incorrect\")\n",
    "    return [l.ljust(20) for l in ret]\n",
    "\n",
    "generate_expression_with_steps(randomer)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "randomer = random.Random(1)\n",
    "\n",
    "from_expression_train_file = open('data/from_expression_train.txt', \"w\")\n",
    "to_expression_train_file = open('data/to_expression_train.txt', \"w\")\n",
    "\n",
    "for i in range(10**6):\n",
    "    steps = generate_expression_with_steps(randomer)\n",
    "    for j in range(len(steps)-1):\n",
    "        from_expression_train_file.write(steps[j] + \"\\n\")\n",
    "        to_expression_train_file.write(steps[j+1] + \"\\n\")\n",
    "\n",
    "from_expression_train_file.close()\n",
    "to_expression_train_file.close()\n",
    "\n",
    "from_expression_test_file = open('data/from_expression_test.txt', \"w\")\n",
    "to_expression_test_file = open('data/to_expression_test.txt', \"w\")\n",
    "\n",
    "for i in range(2 * 10**5):\n",
    "    steps = generate_expression_with_steps(randomer)\n",
    "    for j in range(len(steps)-1):\n",
    "        from_expression_test_file.write(steps[j] + \"\\n\")\n",
    "        to_expression_test_file.write(steps[j+1] + \"\\n\")\n",
    "\n",
    "from_expression_test_file.close()\n",
    "to_expression_test_file.close()\n",
    "\n",
    "from_expression_validation_file = open('data/from_expression_validation.txt', \"w\")\n",
    "to_expression_validation_file = open('data/to_expression_validation.txt', \"w\")\n",
    "\n",
    "for i in range(2 * 10**5):\n",
    "    steps = generate_expression_with_steps(randomer)\n",
    "    for j in range(len(steps)-1):\n",
    "        from_expression_validation_file.write(steps[j] + \"\\n\")\n",
    "        to_expression_validation_file.write(steps[j+1] + \"\\n\")\n",
    "\n",
    "from_expression_validation_file.close()\n",
    "to_expression_validation_file.close()"
   ],
   "metadata": {
    "id": "hYynsbAQL0Ud"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "7roAp9pnkMyX",
    "outputId": "96d76b2c-6f48-4b66-bfc6-b90fc85b9107"
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Good reference https://www.tensorflow.org/tutorials/load_data/text\n",
    "\n",
    "keys = CHAR_VOCAB\n",
    "values = range(2, len(CHAR_VOCAB) + 2)\n",
    "\n",
    "init = tf.lookup.KeyValueTensorInitializer(keys, values, key_dtype=tf.string, value_dtype=tf.int64)\n",
    "\n",
    "num_oov_buckets = 1\n",
    "vocab_table = tf.lookup.StaticVocabularyTable(init, num_oov_buckets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from_expression_train_text_dataset = tf.data.TextLineDataset('data/from_expression_train.txt')\n",
    "to_expression_train_text_dataset = tf.data.TextLineDataset('data/to_expression_train.txt')\n",
    "from_expression_validation_text_dataset = tf.data.TextLineDataset('data/from_expression_validation.txt')\n",
    "to_expression_validation_text_dataset = tf.data.TextLineDataset('data/to_expression_validation.txt')\n",
    "from_expression_test_text_dataset = tf.data.TextLineDataset('data/from_expression_test.txt')\n",
    "to_expression_test_text_dataset = tf.data.TextLineDataset('data/to_expression_test.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  tf.Tensor([50 57 42 52 49 43 55 55 43 51 49 43 54 32 32 32 32 32 32 32], shape=(20,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(20,), dtype=int32, numpy=\narray([50, 57, 42, 52, 49, 43, 55, 55, 43, 51, 49, 43, 54, 32, 32, 32, 32,\n       32, 32, 32], dtype=int32)>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = tf_text.UnicodeCharTokenizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "tokenized_example_ds = from_expression_train_text_dataset.map(tokenize)\n",
    "\n",
    "for text_batch in tokenized_example_ds.take(1):\n",
    "    print(\"Tokens: \", text_batch[0])\n",
    "\n",
    "tokenize(next(from_expression_train_text_dataset.take(1).as_numpy_iterator()))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
